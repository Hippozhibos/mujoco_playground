{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpkYHwCqk7W-"
      },
      "source": [
        "![MuJoCo banner](https://raw.githubusercontent.com/google-deepmind/mujoco/main/banner.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBSdkbmGN2K-"
      },
      "source": [
        "### Copyright notice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UbO9uhtBSX5"
      },
      "source": [
        "> <p><small><small>Copyright 2025 DeepMind Technologies Limited.</small></p>\n",
        "> <p><small><small>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at <a href=\"http://www.apache.org/licenses/LICENSE-2.0\">http://www.apache.org/licenses/LICENSE-2.0</a>.</small></small></p>\n",
        "> <p><small><small>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</small></small></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNIJkb_FM2Ux"
      },
      "source": [
        "# Welcome to MuJoCo Playground! <a href=\"https://colab.research.google.com/github/google-deepmind/mujoco_playground/blob/main/learning/notebooks/welcome_to_the_playground.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" width=\"140\" align=\"center\"/></a>\n",
        "\n",
        "Welcome to MuJoCo Playground, we're excited to meet you! MuJoCo Playground contains a comprehensive suite of environments for reinforcement learning and robotics research. In this notebook, we'll give a tour of [DM Control Suite](https://github.com/google-deepmind/dm_control/tree/main/dm_control/suite) environments that were ported to run on GPU via [MJX](https://mujoco.readthedocs.io/en/stable/mjx.html).\n",
        "\n",
        "**A Colab runtime with GPU acceleration is required.** If you're using a CPU-only runtime, you can switch using the menu \"Runtime > Change runtime type\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Xqo7pyX-n72M"
      },
      "outputs": [],
      "source": [
        "#@title Install pre-requisites\n",
        "!pip install mujoco\n",
        "!pip install mujoco_mjx\n",
        "!pip install brax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IbZxYDxzoz5R"
      },
      "outputs": [],
      "source": [
        "# @title Check if MuJoCo installation was successful\n",
        "\n",
        "import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.'\n",
        "  )\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "try:\n",
        "  print('Checking that the installation succeeded:')\n",
        "  import mujoco\n",
        "\n",
        "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
        "except Exception as e:\n",
        "  raise e from RuntimeError(\n",
        "      'Something went wrong during installation. Check the shell output above '\n",
        "      'for more information.\\n'\n",
        "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
        "      'by going to the Runtime menu and selecting \"Choose runtime type\".'\n",
        "  )\n",
        "\n",
        "print('Installation successful.')\n",
        "\n",
        "# Tell XLA to use Triton GEMM, this improves steps/sec by ~30% on some GPUs\n",
        "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
        "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
        "os.environ['XLA_FLAGS'] = xla_flags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "T5f4w3Kq2X14"
      },
      "outputs": [],
      "source": [
        "# @title Import packages for plotting and creating graphics\n",
        "import itertools\n",
        "import time\n",
        "from typing import Callable, List, NamedTuple, Optional, Union\n",
        "import numpy as np\n",
        "\n",
        "# Graphics and plotting.\n",
        "print(\"Installing mediapy:\")\n",
        "# !command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "# !pip install -q mediapy\n",
        "import mediapy as media\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# More legible printing from numpy.\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "ObF1UXrkb0Nd"
      },
      "outputs": [],
      "source": [
        "# @title Import MuJoCo, MJX, and Brax\n",
        "from datetime import datetime\n",
        "import functools\n",
        "import os\n",
        "from typing import Any, Dict, Sequence, Tuple, Union\n",
        "from brax import base\n",
        "from brax import envs\n",
        "from brax import math\n",
        "from brax.base import Base, Motion, Transform\n",
        "from brax.base import State as PipelineState\n",
        "from brax.envs.base import Env, PipelineEnv, State\n",
        "from brax.io import html, mjcf, model\n",
        "from brax.mjx.base import State as MjxState\n",
        "from brax.training.agents.ppo import networks as ppo_networks\n",
        "from brax.training.agents.ppo import train as ppo\n",
        "from brax.training.agents.sac import networks as sac_networks\n",
        "from brax.training.agents.sac import train as sac\n",
        "from etils import epath\n",
        "from flax import struct\n",
        "from flax.training import orbax_utils\n",
        "from IPython.display import HTML, clear_output\n",
        "import jax\n",
        "from jax import numpy as jp\n",
        "from matplotlib import pyplot as plt\n",
        "import mediapy as media\n",
        "from ml_collections import config_dict\n",
        "import mujoco\n",
        "from mujoco import mjx\n",
        "import numpy as np\n",
        "from orbax import checkpoint as ocp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R01tjWfI-i6"
      },
      "source": [
        "# Intro\n",
        "\n",
        "MuJoCo Playground contains environments for DM Control Suite, Robotic Locomotion, and Robotic Manipulation. You can load any of these environments via the environment registry:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPJeoQeEJBSA"
      },
      "outputs": [],
      "source": [
        "from mujoco_playground import registry\n",
        "env = registry.load('CartpoleBalance_CyberSpine')\n",
        "# env = registry.load('HumanoidWalkCyberSpine')\n",
        "env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env.csp1_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Visualize J\n",
        "import numpy as np\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# åŠ è½½ J.npy\n",
        "J = np.load(\"J.npy\")\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªæ©è”½çŸ©é˜µï¼Œé›¶å€¼æ©è”½ä¸ºç™½è‰²\n",
        "masked_J = np.ma.masked_equal(J, 0)\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„é¢œè‰²å›¾\n",
        "cmap = plt.cm.hot\n",
        "cmap.set_under('lightgray')  # è®¾ç½®ä½äºæœ€å°å€¼ï¼ˆå³é›¶å€¼ï¼‰çš„é¢œè‰²ä¸ºç°è‰²\n",
        "\n",
        "# è°ƒæ•´ figure çš„å¤§å°ï¼Œä½¿å…¶æ›´é€‚åˆçŸ©é˜µçš„å½¢çŠ¶\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# åˆ›å»ºçƒ­å›¾ï¼Œä½¿ç”¨æ©è”½çŸ©é˜µï¼Œå¹¶è®¾ç½®é¢œè‰²\n",
        "im = plt.imshow(masked_J, cmap=cmap, interpolation='nearest', vmax=1, vmin=-1)  # è®¾å®šæœ€å°æ˜¾ç¤ºå€¼\n",
        "\n",
        "# æ·»åŠ æ ‡ç­¾å’Œæ ‡é¢˜\n",
        "plt.title('Jacobian Matrix Heatmap')\n",
        "plt.xlabel('Muscle')\n",
        "plt.ylabel('Joints')\n",
        "\n",
        "# æ˜¾ç¤ºæ¨ªå‘çš„ colorbar\n",
        "cbar = plt.colorbar(im, orientation='horizontal', pad=0.1, aspect=50)  # è®¾ç½®æ¨ªå‘ï¼Œè°ƒæ•´å¤§å°\n",
        "cbar.set_label('Muscle Contribution')  # ä¸º colorbar æ·»åŠ æ ‡ç­¾\n",
        "\n",
        "# æ˜¾ç¤ºçƒ­å›¾\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç¡®å®šæ¯ä¸ªè‚Œè‚‰åˆ—çš„ä¸»è¦å…³èŠ‚ï¼ˆè¡Œï¼‰\n",
        "main_joints = np.argmax(np.abs(J), axis=0)\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œå°†åˆ—ç´¢å¼•æŒ‰ä¸»è¦å…³èŠ‚åˆ†ç»„\n",
        "joint_to_columns = {}\n",
        "for col, joint in enumerate(main_joints):\n",
        "    joint_to_columns.setdefault(joint, []).append(col)\n",
        "\n",
        "# æ ¹æ®è¡Œçš„é¡ºåºé‡æ–°æ’åˆ—åˆ—ç´¢å¼•\n",
        "sorted_columns = []\n",
        "for joint in sorted(joint_to_columns.keys()):\n",
        "    sorted_columns.extend(joint_to_columns[joint])\n",
        "\n",
        "# é‡æ–°æ’åˆ— J çš„åˆ—ï¼Œç”Ÿæˆ J_rearrange\n",
        "J_rearrange = J[:, sorted_columns]\n",
        "\n",
        "# ä¿å­˜ç»“æœ\n",
        "# np.save('J_rearrange.npy', J_rearrange)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºä¸€ä¸ªæ©è”½çŸ©é˜µï¼Œé›¶å€¼æ©è”½ä¸ºç™½è‰²\n",
        "masked_J = np.ma.masked_equal(J_rearrange, 0)\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„é¢œè‰²å›¾\n",
        "cmap = plt.cm.hot\n",
        "cmap.set_under('lightgray')  # è®¾ç½®ä½äºæœ€å°å€¼ï¼ˆå³é›¶å€¼ï¼‰çš„é¢œè‰²ä¸ºç°è‰²\n",
        "\n",
        "# è°ƒæ•´ figure çš„å¤§å°ï¼Œä½¿å…¶æ›´é€‚åˆçŸ©é˜µçš„å½¢çŠ¶\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# åˆ›å»ºçƒ­å›¾ï¼Œä½¿ç”¨æ©è”½çŸ©é˜µï¼Œå¹¶è®¾ç½®é¢œè‰²\n",
        "im = plt.imshow(masked_J, cmap=cmap, interpolation='nearest', vmax=1, vmin=-1)  # è®¾å®šæœ€å°æ˜¾ç¤ºå€¼\n",
        "\n",
        "# æ·»åŠ æ ‡ç­¾å’Œæ ‡é¢˜\n",
        "plt.title('Jacobian Matrix Heatmap')\n",
        "plt.xlabel('Muscle')\n",
        "plt.ylabel('Joints')\n",
        "\n",
        "# æ˜¾ç¤ºæ¨ªå‘çš„ colorbar\n",
        "cbar = plt.colorbar(im, orientation='horizontal', pad=0.1, aspect=50)  # è®¾ç½®æ¨ªå‘ï¼Œè°ƒæ•´å¤§å°\n",
        "cbar.set_label('Muscle Contribution')  # ä¸º colorbar æ·»åŠ æ ‡ç­¾\n",
        "\n",
        "# æ˜¾ç¤ºçƒ­å›¾\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e3MYIKnJnQn"
      },
      "source": [
        "Each environment is also associated with an environment config, which can be overriden if so desired. Let's also load the config:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd8RSkV8JuLe"
      },
      "outputs": [],
      "source": [
        "env_cfg = registry.get_default_config('CartpoleBalance_CyberSpine')\n",
        "env_cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw_y1cVYJzDE"
      },
      "source": [
        "Notice that the environment config contains `sim_dt` and `ctrl_dt`. Each simulation step runs with a timestep of `sim_dt`. `ctrl_dt` determines how much time passes by for each `env.step`. Thus every `env.step` will step the simulation `ctrl_dt / sim_dt` times.\n",
        "\n",
        "Other parameters worth noting are `vision_config`, which we discuss more about in the vision-based notebooks! For now, we'll stick to privileged observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorboardX import SummaryWriter\n",
        "import os\n",
        "\n",
        "# \n",
        "logdir = './logs'\n",
        "os.makedirs(logdir, exist_ok=True)\n",
        "writer = SummaryWriter(logdir=logdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6D8A3zCKn_K"
      },
      "source": [
        "# Rollout\n",
        "\n",
        "Let's now do a simple rollout. This follows closely with the [MJX tutorial notebook](https://colab.sandbox.google.com/github/google-deepmind/mujoco/blob/main/mjx/tutorial.ipynb). If you're familiar with MJX, this should be familiar; otherwise feel free to checkout out the MJX tutorial first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PDGmZ6zGLDws"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g7mZ1DyLDws"
      },
      "outputs": [],
      "source": [
        "state = jit_reset(jax.random.PRNGKey(0))\n",
        "# state = env.reset(jax.random.PRNGKey(0))\n",
        "rollout = [state]\n",
        "\n",
        "f = 0.5\n",
        "for i in range(env_cfg.episode_length):\n",
        "  action = []\n",
        "  for j in range(env.action_size):\n",
        "    action.append(\n",
        "        jp.sin(\n",
        "            state.data.time * 2 * jp.pi * f + j * 2 * jp.pi / env.action_size\n",
        "        )\n",
        "    )\n",
        "  action = jp.array(action)\n",
        "  state = jit_step(state, action)\n",
        "  # state = env.step(state, action)\n",
        "\n",
        "  # print(f\"Length of buffer: {len(env.buffer)}\")\n",
        "  # # æ¯10æ­¥è®°å½•ä¸€æ¬¡æŸå¤±\n",
        "  # if len(env.cc_loss_history) % 10 == 0:\n",
        "  #     writer.add_scalar('CC_net_loss', env.cc_loss_history[-1], i)\n",
        "\n",
        "  rollout.append(state)\n",
        "\n",
        "# writer.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tensorboard --logdir=./logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "frames = env.render(rollout)\n",
        "media.show_video(frames, fps=1.0 / env.dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP8sNROjLc_p"
      },
      "source": [
        "If you're running the notebook with a GPU instance (which you should), notice that the environment runs and lives on the device! That of course means we can do some large-batch RL on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcdKUCt6LDYg"
      },
      "outputs": [],
      "source": [
        "state.obs.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thm7nZueM4cz"
      },
      "source": [
        "# RL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkeGmfKAL2WA"
      },
      "source": [
        "We'll use [brax](https://github.com/google/brax) to train some RL policies, but we show examples with [RSL-RL](https://github.com/google-deepmind/mujoco_playground/tree/main/learning/train_rsl_rl.py) in the main repo via [`python train_rsl_rl.py`](). We encourage `pytorch` users to take a look!\n",
        "\n",
        "For now we'll go ahead with a brax PPO example.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9IfxRqdmQAI"
      },
      "source": [
        "MuJoCo Playground comes with a set of hyper-parameters for all available environments via `mujoco_playground.config`. A selection of environments contain configs for RSL-RL and for vision-based brax PPO. Let's load the brax PPO config for CartpoleBalance!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9T_UVZYLDdM"
      },
      "outputs": [],
      "source": [
        "from mujoco_playground.config import dm_control_suite_params\n",
        "ppo_params = dm_control_suite_params.brax_ppo_config('CartpoleBalance')\n",
        "ppo_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOaeCdOtNtRi"
      },
      "source": [
        "And let's of course train a policy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import functools\n",
        "from mujoco_playground import wrapper\n",
        "from mujoco_playground._src.dm_control_suite import cyber_spine_train\n",
        "\n",
        "# è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯\n",
        "# è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯\n",
        "def train_with_csp1_and_cc(env, ppo_params, csp1_train_state, cc_train_state, num_epochs=1000):\n",
        "    times = [datetime.now()]\n",
        "    \n",
        "    # ä½¿ç”¨PPOçš„è®­ç»ƒå‡½æ•°\n",
        "    ppo_training_params = dict(ppo_params)\n",
        "    network_factory = ppo_networks.make_ppo_networks\n",
        "    if \"network_factory\" in ppo_params:\n",
        "        del ppo_training_params[\"network_factory\"]\n",
        "        network_factory = functools.partial(\n",
        "            ppo_networks.make_ppo_networks,\n",
        "            **ppo_params.network_factory\n",
        "        )\n",
        "\n",
        "    # åˆå§‹åŒ– PPO\n",
        "    train_fn = functools.partial(\n",
        "        ppo.train, **dict(ppo_training_params),\n",
        "        network_factory=network_factory,\n",
        "    )\n",
        "\n",
        "    # åˆå§‹åŒ– PPO å’Œè·å–æ¨ç†å‡½æ•°\n",
        "    make_inference_fn, params, metrics = train_fn(\n",
        "        environment=env,\n",
        "        wrap_env_fn=wrapper.wrap_for_brax_training,\n",
        "    )\n",
        "\n",
        "    # æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯\n",
        "    for epoch in range(num_epochs):\n",
        "        # 1. ä½¿ç”¨PPOè¿›è¡Œè®­ç»ƒï¼Œè·å¾—åŠ¨ä½œã€å¥–åŠ±ç­‰æ•°æ®\n",
        "        action_batch, true_obs_batch = ppo_step()  # è‡ªå®šä¹‰çš„ppo_step()å®ç°\n",
        "\n",
        "        # 2. æ›´æ–°CSP1å’ŒCC_net\n",
        "        # åœ¨æ¯ä¸ªepochæˆ–æ¯ä¸ªæ­¥éª¤åæ›´æ–°CSP1å’ŒCC_net\n",
        "        csp1_train_state, cc_train_state, loss = cyber_spine_train.train_step_joint(csp1_train_state, cc_train_state, action_batch, true_obs_batch)\n",
        "\n",
        "        # 3. åœ¨è®­ç»ƒä¸­ç»§ç»­åŒæ­¥PPOç­–ç•¥ä¸CSP1ã€CC_netçš„è®­ç»ƒ\n",
        "        sync_model_with_ppo(csp1_train_state, cc_train_state)\n",
        "\n",
        "        # è¾“å‡ºè®­ç»ƒä¿¡æ¯\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# ç”¨æ¥æ›´æ–°PPOçš„ç­–ç•¥\n",
        "def ppo_step():\n",
        "    # åœ¨è¿™é‡Œä½¿ç”¨PPOçš„ç­–ç•¥æ›´æ–°ä»£ç è·å–action_batchã€true_obs_batchç­‰æ•°æ®\n",
        "    # è¿™ä¸ªæ­¥éª¤å¯ä»¥é€šè¿‡braxæä¾›çš„trainå‡½æ•°ç”Ÿæˆæ•°æ®\n",
        "    action_batch = jp.ones((10, 5))  # å‡è®¾ç”Ÿæˆäº†ä¸€æ‰¹åŠ¨ä½œæ•°æ®\n",
        "    true_obs_batch = jp.ones((10, 5))  # å‡è®¾ç”Ÿæˆäº†çœŸå®çš„è§‚å¯Ÿæ•°æ®\n",
        "    return action_batch, true_obs_batch\n",
        "\n",
        "def sync_model_with_ppo(csp1_train_state, cc_train_state):\n",
        "    # åœ¨è¿™é‡Œå°†CSP1å’ŒCC_netçš„å‚æ•°ä¸PPOç­–ç•¥è¿›è¡ŒåŒæ­¥\n",
        "    # å¯ä»¥ç”¨PPOçš„ç½‘ç»œå‚æ•°æˆ–è€…çŠ¶æ€æ¥æ›´æ–°å®ƒä»¬\n",
        "    # ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠPPOçš„æ›´æ–°åº”ç”¨åˆ°CSP1å’ŒCC_netçš„è®­ç»ƒçŠ¶æ€ä¸­\n",
        "    # è¿™ä¸ªå‡½æ•°çš„å…·ä½“å®ç°å–å†³äºä½ å¦‚ä½•åŒæ­¥è¿™ä¸¤ä¸ªæ¨¡å‹\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è®­ç»ƒPPO+ CSP1 + CC_net\n",
        "train_with_csp1_and_cc(env, ppo_params, csp1_train_state, cc_train_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBEEQyY6M5OC"
      },
      "source": [
        "### PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XKFzyP7wM5OD"
      },
      "outputs": [],
      "source": [
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  times.append(datetime.now())\n",
        "  x_data.append(num_steps)\n",
        "  y_data.append(metrics[\"eval/episode_reward\"])\n",
        "  y_dataerr.append(metrics[\"eval/episode_reward_std\"])\n",
        "\n",
        "  plt.xlim([0, ppo_params[\"num_timesteps\"] * 1.25])\n",
        "  plt.ylim([0, 1100])\n",
        "  plt.xlabel(\"# environment steps\")\n",
        "  plt.ylabel(\"reward per episode\")\n",
        "  plt.title(f\"y={y_data[-1]:.3f}\")\n",
        "  plt.errorbar(x_data, y_data, yerr=y_dataerr, color=\"blue\")\n",
        "\n",
        "  display(plt.gcf())\n",
        "\n",
        "ppo_training_params = dict(ppo_params)\n",
        "network_factory = ppo_networks.make_ppo_networks\n",
        "if \"network_factory\" in ppo_params:\n",
        "  del ppo_training_params[\"network_factory\"]\n",
        "  network_factory = functools.partial(\n",
        "      ppo_networks.make_ppo_networks,\n",
        "      **ppo_params.network_factory\n",
        "  )\n",
        "\n",
        "train_fn = functools.partial(\n",
        "    ppo.train, **dict(ppo_training_params),\n",
        "    network_factory=network_factory,\n",
        "    progress_fn=progress\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGrlulWbM5OD"
      },
      "outputs": [],
      "source": [
        "from mujoco_playground import wrapper\n",
        "\n",
        "make_inference_fn, params, metrics = train_fn(\n",
        "    environment=env,\n",
        "    wrap_env_fn=wrapper.wrap_for_brax_training,\n",
        ")\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-okEidWPIIg"
      },
      "source": [
        "If you're familiar with brax, you'll notice that we provided a custom wrapper to the `train_fn`. That's because MuJoCo Playground environments are not compatible with the vanilla brax wrappers. For RSL-RL, we ship wrappers in [`wrapper_torch.py`](https://github.com/google-deepmind/mujoco_playground/tree/main/mujoco_playground/_src/wrapper_torch.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHVmccs-oMSo"
      },
      "source": [
        "## Visualize Rollout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sG5a2FFXoUKw"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)\n",
        "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_1CY9xDoUKw"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(42)\n",
        "rollout = []\n",
        "n_episodes = 1\n",
        "\n",
        "for _ in range(n_episodes):\n",
        "  state = jit_reset(rng)\n",
        "  rollout.append(state)\n",
        "  for i in range(env_cfg.episode_length):\n",
        "    act_rng, rng = jax.random.split(rng)\n",
        "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "    state = jit_step(state, ctrl)\n",
        "    rollout.append(state)\n",
        "\n",
        "render_every = 1\n",
        "frames = env.render(rollout[::render_every])\n",
        "rewards = [s.reward for s in rollout]\n",
        "media.show_video(frames, fps=1.0 / env.dt / render_every)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mujoco_playground.config import dm_control_suite_params\n",
        "sac_params = dm_control_suite_params.brax_sac_config('CartpoleBalance')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  times.append(datetime.now())\n",
        "  x_data.append(num_steps)\n",
        "  y_data.append(metrics[\"eval/episode_reward\"])\n",
        "  y_dataerr.append(metrics[\"eval/episode_reward_std\"])\n",
        "\n",
        "  plt.xlim([0, sac_params[\"num_timesteps\"] * 1.25])\n",
        "  plt.ylim([0, 1100])\n",
        "  plt.xlabel(\"# environment steps\")\n",
        "  plt.ylabel(\"reward per episode\")\n",
        "  plt.title(f\"y={y_data[-1]:.3f}\")\n",
        "  plt.errorbar(x_data, y_data, yerr=y_dataerr, color=\"blue\")\n",
        "\n",
        "  display(plt.gcf())\n",
        "\n",
        "sac_training_params = dict(sac_params)\n",
        "network_factory = sac_networks.make_sac_networks\n",
        "if \"network_factory\" in sac_params:\n",
        "  del sac_training_params[\"network_factory\"]\n",
        "  network_factory = functools.partial(\n",
        "      sac_networks.make_sac_networks,\n",
        "      **sac_params.network_factory\n",
        "  )\n",
        "\n",
        "train_fn = functools.partial(\n",
        "    sac.train, **dict(sac_training_params),\n",
        "    network_factory=network_factory,\n",
        "    progress_fn=progress\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "make_inference_fn, params, metrics = train_fn(\n",
        "    environment=env,\n",
        "    wrap_env_fn=wrapper.wrap_for_brax_training,\n",
        ")\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)\n",
        "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "rollout = []\n",
        "n_episodes = 1\n",
        "\n",
        "for _ in range(n_episodes):\n",
        "  state = jit_reset(rng)\n",
        "  rollout.append(state)\n",
        "  for i in range(env_cfg.episode_length):\n",
        "    act_rng, rng = jax.random.split(rng)\n",
        "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "    state = jit_step(state, ctrl)\n",
        "    rollout.append(state)\n",
        "\n",
        "render_every = 1\n",
        "frames = env.render(rollout[::render_every])\n",
        "rewards = [s.reward for s in rollout]\n",
        "media.show_video(frames, fps=1.0 / env.dt / render_every)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3NXzZCjTskz"
      },
      "source": [
        "# DM Control Suite - Take a spin!\n",
        "\n",
        "Feel free to now take a spin on any of the DM Control Suite environments! The world is your oyster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "CilNmELAdeNk"
      },
      "outputs": [],
      "source": [
        "env_name = \"HumanoidWalk\"  # @param [\"AcrobotSwingup\", \n",
        "                        # \"AcrobotSwingupSparse\", \n",
        "                        # \"BallInCup\", \n",
        "                        # \"CartpoleBalance\", \n",
        "                        # \"CartpoleBalanceSparse\", \n",
        "                        # \"CartpoleSwingup\", \n",
        "                        # \"CartpoleSwingupSparse\", \n",
        "                        # \"CheetahRun\", \n",
        "                        # \"FingerSpin\", \n",
        "                        # \"FingerTurnEasy\", \n",
        "                        # \"FingerTurnHard\", \n",
        "                        # \"FishSwim\", \n",
        "                        # \"HopperHop\", \n",
        "                        # \"HopperStand\", \n",
        "                        # \"HumanoidStand\", \n",
        "                        # \"HumanoidWalk\", \n",
        "                        # \"HumanoidRun\", \n",
        "                        # \"PendulumSwingup\", \n",
        "                        # \"PointMass\", \n",
        "                        # \"ReacherEasy\", \n",
        "                        # \"ReacherHard\", \n",
        "                        # \"SwimmerSwimmer6\", \n",
        "                        # \"WalkerRun\", \n",
        "                        # \"WalkerStand\", \n",
        "                        # \"WalkerWalk\"]\n",
        "CAMERAS = {\n",
        "    \"AcrobotSwingup\": \"fixed\",\n",
        "    \"AcrobotSwingupSparse\": \"fixed\",\n",
        "    \"BallInCup\": \"cam0\",\n",
        "    \"CartpoleBalance\": \"fixed\",\n",
        "    \"CartpoleBalanceSparse\": \"fixed\",\n",
        "    \"CartpoleSwingup\": \"fixed\",\n",
        "    \"CartpoleSwingupSparse\": \"fixed\",\n",
        "    \"CheetahRun\": \"side\",\n",
        "    \"FingerSpin\": \"cam0\",\n",
        "    \"FingerTurnEasy\": \"cam0\",\n",
        "    \"FingerTurnHard\": \"cam0\",\n",
        "    \"FishSwim\": \"fixed_top\",\n",
        "    \"HopperHop\": \"cam0\",\n",
        "    \"HopperStand\": \"cam0\",\n",
        "    \"HumanoidStand\": \"side\",\n",
        "    \"HumanoidWalk\": \"side\",\n",
        "    \"HumanoidRun\": \"side\",\n",
        "    \"PendulumSwingup\": \"fixed\",\n",
        "    \"PointMass\": \"cam0\",\n",
        "    \"ReacherEasy\": \"fixed\",\n",
        "    \"ReacherHard\": \"fixed\",\n",
        "    \"SwimmerSwimmer6\": \"tracking1\",\n",
        "    \"WalkerRun\": \"side\",\n",
        "    \"WalkerWalk\": \"side\",\n",
        "    \"WalkerStand\": \"side\",\n",
        "}\n",
        "camera_name = CAMERAS[env_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "env_name = \"CyberMiceWalk\"\n",
        "\n",
        "camera_name = \"side\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6m1K6y4IOUj_"
      },
      "outputs": [],
      "source": [
        "from mujoco_playground import registry\n",
        "\n",
        "env_cfg = registry.get_default_config(env_name)\n",
        "env = registry.load(env_name, config=env_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLHkrJhAOUj_"
      },
      "source": [
        "## Visualize the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9Ry7wWduOUkA"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR5DX0SWOUkA"
      },
      "outputs": [],
      "source": [
        "state = jit_reset(jax.random.PRNGKey(0))\n",
        "rollout = [state]\n",
        "\n",
        "f = 0.5\n",
        "for i in range(env_cfg.episode_length):\n",
        "  action = []\n",
        "  for j in range(env.action_size):\n",
        "    action.append(\n",
        "        jp.sin(\n",
        "            state.data.time * 2 * jp.pi * f + j * 2 * jp.pi / env.action_size\n",
        "        )\n",
        "    )\n",
        "  action = jp.array(action)\n",
        "  state = jit_step(state, action)\n",
        "  rollout.append(state)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frames = env.render(rollout, camera = camera_name)\n",
        "media.show_video(frames, fps=1.0 / env.dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuI8_ioCOUkB"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "afAaOGzSoNMd"
      },
      "outputs": [],
      "source": [
        "from mujoco_playground.config import dm_control_suite_params\n",
        "from mujoco_playground import wrapper\n",
        "\n",
        "ppo_params = dm_control_suite_params.brax_ppo_config(env_name)\n",
        "sac_params = dm_control_suite_params.brax_sac_config(env_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(ppo_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5MNLlatbS27"
      },
      "source": [
        "### PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "N5KgRSAZbSEX"
      },
      "outputs": [],
      "source": [
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  times.append(datetime.now())\n",
        "  x_data.append(num_steps)\n",
        "  y_data.append(metrics[\"eval/episode_reward\"])\n",
        "  y_dataerr.append(metrics[\"eval/episode_reward_std\"])\n",
        "\n",
        "  plt.xlim([0, ppo_params[\"num_timesteps\"] * 1.25])\n",
        "  plt.ylim([0, 1100])\n",
        "  plt.xlabel(\"# environment steps\")\n",
        "  plt.ylabel(\"reward per episode\")\n",
        "  plt.title(f\"y={y_data[-1]:.3f}\")\n",
        "  plt.errorbar(x_data, y_data, yerr=y_dataerr, color=\"blue\")\n",
        "\n",
        "  display(plt.gcf())\n",
        "\n",
        "ppo_training_params = dict(ppo_params)\n",
        "network_factory = ppo_networks.make_ppo_networks\n",
        "if \"network_factory\" in ppo_params:\n",
        "  del ppo_training_params[\"network_factory\"]\n",
        "  network_factory = functools.partial(\n",
        "      ppo_networks.make_ppo_networks,\n",
        "      **ppo_params.network_factory\n",
        "  )\n",
        "\n",
        "train_fn = functools.partial(\n",
        "    ppo.train, **dict(ppo_training_params),\n",
        "    network_factory=network_factory,\n",
        "    progress_fn=progress\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrD6T1VWbSJD"
      },
      "outputs": [],
      "source": [
        "make_inference_fn, params, metrics = train_fn(\n",
        "    environment=env,\n",
        "    wrap_env_fn=wrapper.wrap_for_brax_training,\n",
        ")\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "80esJi__b6J2"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)\n",
        "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HsbR2AIRb6J2"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(42)\n",
        "rollout = []\n",
        "n_episodes = 1\n",
        "\n",
        "for _ in range(n_episodes):\n",
        "  state = jit_reset(rng)\n",
        "  rollout.append(state)\n",
        "  for i in range(env_cfg.episode_length):\n",
        "    act_rng, rng = jax.random.split(rng)\n",
        "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "    state = jit_step(state, ctrl)\n",
        "    rollout.append(state)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "render_every = 1\n",
        "frames = env.render(rollout[::render_every], camera=camera_name)\n",
        "rewards = [s.reward for s in rollout]\n",
        "media.show_video(frames, fps=1.0 / env.dt / render_every)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpRJnuuXb7Ax"
      },
      "source": [
        "### SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "besM1HxqOUkB"
      },
      "outputs": [],
      "source": [
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  times.append(datetime.now())\n",
        "  x_data.append(num_steps)\n",
        "  y_data.append(metrics[\"eval/episode_reward\"])\n",
        "  y_dataerr.append(metrics[\"eval/episode_reward_std\"])\n",
        "\n",
        "  plt.xlim([0, sac_params[\"num_timesteps\"] * 1.25])\n",
        "  plt.ylim([0, 1100])\n",
        "  plt.xlabel(\"# environment steps\")\n",
        "  plt.ylabel(\"reward per episode\")\n",
        "  plt.title(f\"y={y_data[-1]:.3f}\")\n",
        "  plt.errorbar(x_data, y_data, yerr=y_dataerr, color=\"blue\")\n",
        "\n",
        "  display(plt.gcf())\n",
        "\n",
        "sac_training_params = dict(sac_params)\n",
        "network_factory = sac_networks.make_sac_networks\n",
        "if \"network_factory\" in sac_params:\n",
        "  del sac_training_params[\"network_factory\"]\n",
        "  network_factory = functools.partial(\n",
        "      sac_networks.make_sac_networks,\n",
        "      **sac_params.network_factory\n",
        "  )\n",
        "\n",
        "train_fn = functools.partial(\n",
        "    sac.train, **dict(sac_training_params),\n",
        "    network_factory=network_factory,\n",
        "    progress_fn=progress\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkKerfRjOUkB"
      },
      "outputs": [],
      "source": [
        "make_inference_fn, params, metrics = train_fn(\n",
        "    environment=env,\n",
        "    wrap_env_fn=wrapper.wrap_for_brax_training,\n",
        ")\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Yw_vewrKOUkB"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)\n",
        "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJFfqcwoOUkB"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "rollout = []\n",
        "n_episodes = 1\n",
        "\n",
        "for _ in range(n_episodes):\n",
        "  state = jit_reset(rng)\n",
        "  rollout.append(state)\n",
        "  for i in range(env_cfg.episode_length):\n",
        "    act_rng, rng = jax.random.split(rng)\n",
        "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "    state = jit_step(state, ctrl)\n",
        "    rollout.append(state)\n",
        "\n",
        "render_every = 1\n",
        "frames = env.render(rollout[::render_every])\n",
        "rewards = [s.reward for s in rollout]\n",
        "media.show_video(frames, fps=1.0 / env.dt / render_every)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtrAqns35sI"
      },
      "source": [
        "ğŸ™Œ See you soon!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
